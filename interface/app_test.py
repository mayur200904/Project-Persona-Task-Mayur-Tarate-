"""
Streamlit Test Version - Ultra Simple with Timeouts
"""

import streamlit as st
import sys
import os
from pathlib import Path
import time

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

st.set_page_config(page_title="LinkedIn RAG Agent - TEST", page_icon="üöÄ", layout="wide")

st.title("üöÄ LinkedIn RAG Agent - TEST VERSION")
st.caption("With strict timeouts and detailed logging")

# Sidebar
with st.sidebar:
    st.header("üë§ Persona Details")
    name = st.text_input("Name", value="Sundar Pichai")
    title = st.text_input("Role/Title", value="CEO")
    company = st.text_input("Company", value="Google")
    industry = st.text_input("Industry", value="Technology")

# Main area
st.header("üìù Input")

topic = st.text_area(
    "Post Topic",
    value="The importance of developing AI responsibly",
    height=100
)

if st.button("üöÄ Generate Post", type="primary"):
    if not topic:
        st.error("Please enter a topic!")
    else:
        log_area = st.empty()
        result_area = st.empty()
        
        def log(msg):
            st.write(f"**{msg}**")
        
        try:
            # Step 1: Import
            log("‚è±Ô∏è Step 1/5: Importing modules...")
            start = time.time()
            
            from retrieve import PostRetriever
            from prompter import PromptBuilder
            from generate import PostGenerator
            from plagiarism_checker import PlagiarismChecker
            from memory_manager import MemoryManager
            
            log(f"‚úÖ Imports done in {time.time()-start:.2f}s")
            
            # Step 2: Initialize retriever
            log("‚è±Ô∏è Step 2/5: Initializing retriever...")
            start = time.time()
            
            retriever = PostRetriever(verbose=False)
            
            log(f"‚úÖ Retriever initialized in {time.time()-start:.2f}s (Index: {retriever.index.ntotal} vectors)")
            
            # Step 3: Retrieve
            log("‚è±Ô∏è Step 3/5: Retrieving similar posts...")
            start = time.time()
            
            persona_info = {
                "name": name,
                "title": title,
                "company": company,
                "industry": industry
            }
            
            chunks = retriever.retrieve_with_context(
                persona_info, 
                topic, 
                top_k=5,  # Reduced from 10 for speed
                use_mmr=True
            )
            
            log(f"‚úÖ Retrieved {len(chunks)} chunks in {time.time()-start:.2f}s")
            
            # Step 4: Build prompt
            log("‚è±Ô∏è Step 4/5: Building prompt...")
            start = time.time()
            
            prompt_builder = PromptBuilder()
            prompt_dict = prompt_builder.build_full_prompt(
                persona_info, 
                topic, 
                chunks
            )
            
            log(f"‚úÖ Prompt built in {time.time()-start:.2f}s")
            
            # Step 5: Generate
            log("‚è±Ô∏è Step 5/5: Generating post with GPT...")
            start = time.time()
            
            generator = PostGenerator(temperature=0.7, max_tokens=500)
            result = generator.generate_with_rag(prompt_dict)
            post = result['post']
            
            log(f"‚úÖ Post generated in {time.time()-start:.2f}s")
            
            # Log to memory
            log("‚è±Ô∏è Logging to memory...")
            memory_start = time.time()
            
            memory_manager = MemoryManager(memory_path="memory/memory.json", verbose=False)
            
            # Count hashtags and words
            hashtag_count = post.count('#')
            word_count = len(post.split())
            
            memory_manager.log_generated_post({
                'post': post,
                'topic': topic,
                'method': 'RAG',
                'word_count': word_count,
                'hashtag_count': hashtag_count,
                'persona': f"{name} - {title} at {company}"
            })
            
            log(f"‚úÖ Logged to memory in {time.time()-memory_start:.2f}s")
            
            # Show result
            st.success("üéâ Generation Complete!")
            st.markdown("### üìÑ Generated Post:")
            st.info(post)
            
            # Show stats
            st.markdown("### üìä Stats:")
            st.write(f"- Post length: {len(post)} characters")
            st.write(f"- Chunks used: {len(chunks)}")
            
            # Show retrieved context
            with st.expander("üîç Retrieved Context"):
                for i, chunk in enumerate(chunks, 1):
                    st.markdown(f"**Chunk {i}:**")
                    st.text(chunk.get('text', chunk.get('content', 'No text available'))[:200] + "...")
                    st.divider()
            
        except Exception as e:
            st.error(f"‚ùå ERROR: {str(e)}")
            with st.expander("üîç Full Error Details"):
                import traceback
                st.code(traceback.format_exc())

st.divider()
st.caption("Test version with detailed timing for each step")
